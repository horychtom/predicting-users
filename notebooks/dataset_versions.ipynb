{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display_html\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_dfs(dfs, gap=50, justify='center'):\n",
    "    html = \"\"\n",
    "    for title, df in dfs.items():  \n",
    "        df_html = df._repr_html_()\n",
    "        cur_html = f'<div> <h3>{title}</h3> {df_html}</div>'\n",
    "        html +=  cur_html\n",
    "    html= f\"\"\"\n",
    "    <div style=\"display:flex; gap:{gap}px; justify-content:{justify};\">\n",
    "        {html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display_html(html, raw=True)\n",
    "\n",
    "def mynorm(arr):\n",
    "    return (arr-arr.min())/(arr.max() - arr.min())\n",
    "\n",
    "\n",
    "def remove_outliers(d,cols_=['y']):\n",
    "    d=d.copy()\n",
    "    cols = cols_ # one or more\n",
    "\n",
    "    Q1 = d[cols].quantile(0.25)\n",
    "    Q3 = d[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    d = d[~((d[cols] < (Q1 - 2 * IQR)) |(d[cols] > (Q3 + 2 * IQR))).any(axis=1)]\n",
    "    d['y'] = mynorm(d.y)\n",
    "    return d\n",
    "\n",
    "\n",
    "def plot_corr(df,var):\n",
    "    sns.regplot(x=mynorm(df[var]),y=mynorm(df.y),order=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            tmp = df[df[r].notnull() & df[c].notnull()]\n",
    "            pvalues[r][c] = round(pearsonr(tmp[r], tmp[c])[1], 4)\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('../datasets/datasets_final.csv')\n",
    "d['seo_subj'] = d[['seo_subj','seo_subj2']].mean(axis=1)\n",
    "d=d[['id','seo_complex2','seo_veracity','seo_loaded','seo_mb',\n",
    "   'seo_pers','seo_sento','seo_subj',\n",
    "   'publish_date_cest','channel','access_level','seo_title','y','body_mb','body_pers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=d.rename(columns={'seo_complex2':'language_complexity','seo_veracity':'inversed_veracity','seo_loaded':'loaded_language',\n",
    "                  'seo_mb':'generalized_bias','seo_pers':'persuasivness','seo_sento':'sentiment','seo_subj':'subjective_bias',\n",
    "                  'body_mb':'body_bias_score','body_pers':'body_persuasive_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d[d.channel.isin(list(d.groupby('channel').count().sort_values(by='id').reset_index()['channel'][-14:]))]\n",
    "df = d.copy()\n",
    "df = df[df.access_level != 'conditional']\n",
    "# df.y = mynorm(df.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_bias_metric']=df[['loaded_language','subjective_bias','generalized_bias','persuasivness','inversed_veracity']].mean(axis=1)\n",
    "df['body_bias_metric']=df[['body_bias_score','body_persuasive_score']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.publish_date_cest.apply(lambda x: str(x)[5:7])\n",
    "df['day'] = df.publish_date_cest.apply(lambda x: str(x)[:10])\n",
    "\n",
    "df_sorted=df.sort_values(by='day')\n",
    "df_sorted_f=df_sorted[df_sorted.access_level=='free'].groupby('day').mean()\n",
    "df_sorted_p=df_sorted[df_sorted.access_level=='paid'].groupby('day').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus=df[df.channel == 'Ausland'].sort_values(by='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = []\n",
    "week_counter = 0\n",
    "sunday = False\n",
    "for idx, row in aus.iterrows():\n",
    "    day = int(row['day'][-2:])\n",
    "    if day%7 == 0 and not sunday:\n",
    "        week_counter+=1\n",
    "        sunday = True\n",
    "    if day%7 != 0 and sunday:\n",
    "        sunday = False\n",
    "    weeks.append(week_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus['week'] = weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus['y'] = mynorm(aus.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynorm(aus.groupby('week').mean().sort_values(by='inversed_veracity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus[aus.week.isin([20,21,22])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.groupby(by='month').agg(['mean','sem'])\n",
    "d1 = stats['seo_complex2']\n",
    "d1['ci95_hi'] = d1['mean'] + 1.96* d1['sem']\n",
    "d1['ci95_lo'] = d1['mean'] - 1.96* d1['sem']\n",
    "import matplotlib.pyplot as plt\n",
    "sns.lineplot(x=np.arange(len(d1['mean'])),y=d1['mean'],ci=None)\n",
    "plt.fill_between(np.arange(len(d1['mean'])),d1['ci95_hi'], d1['ci95_lo'], color='blue', alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd_all = df.groupby(by='day').mean()\n",
    "gbm_all = df.groupby(by='month').mean()\n",
    "gbw_all = df_sorted.groupby(np.arange(len(df_sorted))//7, axis=0).mean()\n",
    "gbmp_all = df[df.access_level=='paid'].groupby(by='month').mean()\n",
    "gbdp_all = df[df.access_level=='paid'].groupby(by='day').mean()\n",
    "gbmf_all = df[df.access_level=='free'].groupby(by='month').mean()\n",
    "gbdf_all = df[df.access_level=='free'].groupby(by='day').mean()\n",
    "gbwf_all =df_sorted_f.groupby(np.arange(len(df_sorted_f.index))//7, axis=0).mean()\n",
    "gbwp_all = df_sorted_p.groupby(np.arange(len(df_sorted_p.index))//7, axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_topic(d):\n",
    "    d['month'] = d.publish_date_cest.apply(lambda x: str(x)[5:7])\n",
    "    d['day'] = d.publish_date_cest.apply(lambda x: str(x)[:10])\n",
    "\n",
    "    topics = d.groupby('channel').count().sort_values(by='id').reset_index()['channel'][-14:]\n",
    "\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "        \n",
    "        df = d[d.channel == topic]\n",
    "        print(\"Full length:\",len(df))\n",
    "\n",
    "\n",
    "        df_sorted=df.sort_values(by='day')\n",
    "        df_sorted_f=df_sorted[df_sorted.access_level=='free'].groupby('day').mean()\n",
    "        df_sorted_p=df_sorted[df_sorted.access_level=='paid'].groupby('day').mean()\n",
    "        print(\"Free to paid ratio:\",len(df_sorted[df_sorted.access_level=='free'])/(len(df_sorted[df_sorted.access_level=='free'])+len(df_sorted[df_sorted.access_level=='paid'])))\n",
    "        df_sorted_fp = df_sorted.groupby('day').mean()\n",
    "\n",
    "\n",
    "        gbwf =df_sorted_f.groupby(np.arange(len(df_sorted_f.index))//7, axis=0).mean()\n",
    "        gbwp = df_sorted_p.groupby(np.arange(len(df_sorted_p.index))//7, axis=0).mean()\n",
    "        gbw = df_sorted_fp.groupby(np.arange(len(df_sorted_fp.index))//7, axis=0).mean()\n",
    "        gbwf_corrs = remove_outliers(gbwf).corr().y.sort_values().reset_index()\n",
    "        gbwp_corrs = remove_outliers(gbwp).corr().y.sort_values().reset_index()\n",
    "        gbw_corrs = remove_outliers(gbw).corr().y.sort_values().reset_index()\n",
    "        print(\"Final number of months:\",len(remove_outliers(gbw)))\n",
    "\n",
    "        print(np.corrcoef(remove_outliers(gbwf).corr().y,remove_outliers(gbwp).corr().y)[0][1])\n",
    "\n",
    "        dfs = {'free':gbwf_corrs,'paid':gbwp_corrs, 'both':gbw_corrs}\n",
    "        display_dfs(dfs, justify='flex-start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_topic2(d):\n",
    "    d['month'] = d.publish_date_cest.apply(lambda x: str(x)[5:7])\n",
    "    d['day'] = d.publish_date_cest.apply(lambda x: str(x)[:10])\n",
    "\n",
    "    # topics = d.groupby('channel').count().sort_values(by='id').reset_index()['channel'][-14:]\n",
    "    topics = ['Wissenschaft','Ausland','Psychologie']\n",
    "\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "        \n",
    "        df = d[d.channel == topic]\n",
    "        print(\"Full length:\",len(df))\n",
    "\n",
    "\n",
    "        df_sorted=df.sort_values(by='day')\n",
    "        gbwf=bla(remove_outliers(df_sorted[df_sorted.access_level=='free'].groupby('day').mean()))\n",
    "        gbwp=bla(remove_outliers(df_sorted[df_sorted.access_level=='paid'].groupby('day').mean()))\n",
    "        print(\"Free to paid ratio:\",len(df_sorted[df_sorted.access_level=='free'])/(len(df_sorted[df_sorted.access_level=='free'])+len(df_sorted[df_sorted.access_level=='paid'])))\n",
    "        gbw =bla(remove_outliers(df_sorted.groupby('day').mean()))\n",
    "\n",
    "\n",
    "        gbwf_corrs = gbwf.corr().y.sort_values().reset_index()\n",
    "        gbwp_corrs = gbwp.corr().y.sort_values().reset_index()\n",
    "        gbw_corrs = gbw.corr().y.sort_values().reset_index()\n",
    "        print(\"Final number of months:\",len(gbw))\n",
    "\n",
    "        print(np.corrcoef(gbwf.corr().y,gbwp.corr().y)[0][1])\n",
    "\n",
    "        dfs = {'free':gbwf_corrs,'paid':gbwp_corrs, 'both':gbw_corrs}\n",
    "        display_dfs(dfs, justify='flex-start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corefs(d):\n",
    "    d['month'] = d.publish_date_cest.apply(lambda x: str(x)[5:7])\n",
    "    d['day'] = d.publish_date_cest.apply(lambda x: str(x)[:10])\n",
    "\n",
    "    topics = d.groupby('channel').count().sort_values(by='id').reset_index()['channel'][-14:]\n",
    "    corefs=[]\n",
    "    for topic in topics:        \n",
    "        df = d[d.channel == topic]\n",
    "        df_sorted=df.sort_values(by='day')\n",
    "        df_sorted_f=df_sorted[df_sorted.access_level=='free'].groupby('day').mean()\n",
    "        df_sorted_p=df_sorted[df_sorted.access_level=='paid'].groupby('day').mean()\n",
    "\n",
    "\n",
    "        gbwf =df_sorted_f.groupby(np.arange(len(df_sorted_f.index))//7, axis=0).mean()\n",
    "        gbwp = df_sorted_p.groupby(np.arange(len(df_sorted_p.index))//7, axis=0).mean()\n",
    "\n",
    "        corefs.append({'topic':topic,'corr':np.corrcoef(remove_outliers(gbwf).corr().y,remove_outliers(gbwp).corr().y)[0][1]})\n",
    "\n",
    "    return pd.DataFrame(corefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=get_corefs(df).sort_values(by='corr')[:-1],x='topic',y='corr')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_week(df,topic):\n",
    "    df = df[df.channel == topic]\n",
    "\n",
    "    df_sorted=df.sort_values(by='day')\n",
    "    df_sorted_f=df_sorted[df_sorted.access_level=='free'].groupby('day').mean()\n",
    "    df_sorted_p=df_sorted[df_sorted.access_level=='paid'].groupby('day').mean()\n",
    "    df_sorted_fp = df_sorted.groupby('day').mean()\n",
    "\n",
    "\n",
    "    gbwf = remove_outliers(df_sorted_f.groupby(np.arange(len(df_sorted_f.index))//7, axis=0).mean())\n",
    "    gbwp = remove_outliers(df_sorted_p.groupby(np.arange(len(df_sorted_p.index))//7, axis=0).mean())\n",
    "    gbw = remove_outliers(df_sorted_fp.groupby(np.arange(len(df_sorted_fp.index))//7, axis=0).mean())\n",
    "\n",
    "    return gbwf,gbwp,gbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_month(df,topic):\n",
    "    df = df[df.channel == topic]\n",
    "\n",
    "    gbwf = remove_outliers(df[df.access_level=='free'].groupby('month').mean())\n",
    "    gbwp = remove_outliers(df[df.access_level=='paid'].groupby('month').mean())\n",
    "    gbw = remove_outliers(df.groupby(\"month\").mean())\n",
    "\n",
    "    return gbwf,gbwp,gbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_day(df,topic):\n",
    "    df = df[df.channel == topic]\n",
    "\n",
    "    gbwf = bla(remove_outliers(df[df.access_level=='free'].groupby('day').mean()))\n",
    "    gbwp = bla(remove_outliers(df[df.access_level=='paid'].groupby('day').mean()))\n",
    "    gbw = bla(remove_outliers(df.groupby(\"day\").mean()))\n",
    "\n",
    "    return gbwf,gbwp,gbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def bla(d):\n",
    "        return mynorm(d.rolling(window=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_topic2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bla(d):\n",
    "    return mynorm(d.ewm(alpha=0.1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Ausland')\n",
    "mask=(calculate_pvalues(gbw)>0.05).astype(int)\n",
    "sns.heatmap(gbw.corr(),mask=mask,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbw.corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbwf.corr().y.drop('y'),marker='o')\n",
    "sns.lineplot(gbwp.corr().y.drop('y'),marker='o')\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbw['y'])\n",
    "sns.lineplot(gbw['subjective_bias'],color='#F29492')\n",
    "plt.xticks([])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel('days')\n",
    "# sns.lineplot(mynorm(gbw['seo_subj'].ewm(alpha=0.05).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=mynorm(gbwf['subjective_bias']),y=mynorm(gbwf.y),order=1)\n",
    "plt.ylabel('#pageviews')\n",
    "plt.xlabel(\"bias of the article\")\n",
    "\n",
    "# plot_corr(gbwf,'subjective_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\", {'grid.linestyle': '--'})\n",
    "sns.lineplot(gbwf['y'])\n",
    "sns.lineplot(gbwf['body_bias_metric'],color='#F29492')\n",
    "plt.xticks([])\n",
    "\n",
    "# sns.lineplot(mynorm(gbw['seo_subj'].ewm(alpha=0.05).mean()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wissenschaft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Wissenschaft')\n",
    "\n",
    "sns.lineplot(gbw['y'])\n",
    "# sns.lineplot(gbw['y'],alpha=0.2)\n",
    "sns.lineplot(gbw['body_persuasive_score'],color='#F29492')\n",
    "# sns.lineplot(gbw['body_bias_metric'],alpha=0.2)\n",
    "plt.xticks([])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "# sns.lineplot(gbw['seo_title_multibias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Wissenschaft')\n",
    "\n",
    "sns.lineplot(gbw['y'])\n",
    "# sns.lineplot(gbw['y'],alpha=0.2)\n",
    "sns.lineplot(gbw['language_complexity'],color='#F29492')\n",
    "# sns.lineplot(gbw['body_bias_metric'],alpha=0.2)\n",
    "plt.xticks([])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "# sns.lineplot(gbw['seo_title_multibias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Psychologie')\n",
    "\n",
    "sns.lineplot(gbw['y'])\n",
    "# sns.lineplot(gbw['y'],alpha=0.2)\n",
    "sns.lineplot(mynorm(gbw['language_complexity']),color='#F29492')\n",
    "# sns.lineplot(gbw['body_bias_metric'],alpha=0.2)\n",
    "plt.xticks([])\n",
    "# sns.lineplot(gbw['seo_title_multibias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Psychologie')\n",
    "\n",
    "sns.lineplot(gbw['y'])\n",
    "# sns.lineplot(gbw['y'],alpha=0.2)\n",
    "sns.lineplot(gbw['language_complexity'],color='#F29492')\n",
    "# sns.lineplot(gbw['body_bias_metric'],alpha=0.2)\n",
    "plt.xticks([])\n",
    "\n",
    "# sns.lineplot(gbw['seo_title_multibias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psychologie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_day(df,'Psychologie')\n",
    "\n",
    "sns.lineplot(gbw['y'].rolling(window=5).mean())\n",
    "# sns.lineplot(gbw['y'],alpha=0.2)\n",
    "sns.lineplot(gbw['body_bias_metric'].rolling(window=5).mean())\n",
    "# sns.lineplot(gbw['body_bias_metric'],alpha=0.2)\n",
    "plt.xticks([])\n",
    "\n",
    "# sns.lineplot(gbw['seo_title_multibias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbwf.corr().y.drop('y'),marker='o')\n",
    "sns.lineplot(gbwp.corr().y.drop('y'),marker='o')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbwp['y'])\n",
    "sns.lineplot(gbwp['language_complexity'])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbw['y'])\n",
    "sns.lineplot(gbw['body_bias_metric'])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(mynorm(gbw['y'].ewm(alpha=0.1).mean()))\n",
    "sns.lineplot(mynorm(gbw['seo_veracity'].ewm(alpha=0.1).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(mynorm(gbd_all['y'].ewm(alpha=0.01).mean()))\n",
    "sns.lineplot(mynorm(gbd_all['inversed_veracity'].ewm(alpha=0.01).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bla(d):\n",
    "    return mynorm(d.ewm(alpha=0.01).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd_all_bla = bla(gbd_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd_all_bla.corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd_all_bla = remove_outliers(gbd_all_bla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gbd_all_bla['y'])\n",
    "sns.lineplot(gbd_all_bla['language_complexity'],legend=True,color='#F29492')\n",
    "plt.xticks([])\n",
    "plt.ylabel('')\n",
    "plt.xlabel('days')\n",
    "# plt.savefig('../images/bb.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=mynorm(gbd_all_bla['language_complexity']),y=mynorm(gbd_all_bla.y),order=1)\n",
    "plt.ylabel('#pageviews')\n",
    "plt.xlabel(\"bias of the article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blabla.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(blabla['y'][10:])\n",
    "sns.lineplot(blabla['body_bias_score'][10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(bla(df[df.access_level=='free'])['y'])\n",
    "sns.lineplot(bla(df[df.access_level=='free'])['body_bias_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynorm(gbdp_all['y'].ewm(alpha=0.1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla(df).corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bla(gbd_all)).corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(bla(gbd_all)['y'][1:-1])\n",
    "sns.lineplot(bla(gbd_all)['language_complexity'][1:-1])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bla(gbdp_all)).corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bla(gbdp_all)).corr().y.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = d.groupby('channel').count().sort_values(by='id').reset_index()['channel'][-14:]\n",
    "ddd = pd.DataFrame()\n",
    "\n",
    "for t in topics:\n",
    "    _,dd,_ = get_topic_day(df,t)\n",
    "    ddd[t] = dd.corr().y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdp_all.corr().y.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.abs().to_numpy().reshape(12*14).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.abs().fillna(0).to_numpy().reshape(12*14).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(bla(gbdf_all).corr().y,bla(gbdp_all).corr().y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ddd.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = df[['seo_complex2', 'seo_veracity', 'seo_loaded', 'seo_mb',\n",
    "       'seo_pers', 'seo_sento', 'seo_subj', 'channel',\n",
    "       'access_level', 'y', 'body_mb', 'body_pers',\n",
    "       'seo_title_multibias', 'body_bias_metric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=d1[d1.channel=='Wissenschaft'].drop(columns=['access_level','channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from copy import deepcopy\n",
    "features = mynorm(data.drop(columns=['y']))\n",
    "labels = mynorm(data['y'])\n",
    "\n",
    "max_score = 0\n",
    "best_clf = None\n",
    "for i in tqdm(range(1000)):\n",
    "    X_train,X_dev,y_train,y_dev = train_test_split(features,labels,test_size=0.3)\n",
    "    X_dev,X_test,y_dev,y_test = train_test_split(X_dev,y_dev,test_size=0.5)\n",
    "    clf = DecisionTreeRegressor(max_depth=3,random_state=i)\n",
    "    clf.fit(features,labels)\n",
    "\n",
    "    result = r2_score(y_dev,clf.predict(X_dev))\n",
    "    if result > max_score:\n",
    "        print(result)\n",
    "        max_score = result\n",
    "        best_clf = deepcopy(clf)\n",
    "        print(\"on test\",r2_score(y_test,clf.predict(X_test)))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def LOOCV(clf,train_data):\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    # initialize a list to store the scores\n",
    "    scores = []\n",
    "\n",
    "    X = train_data.drop(columns=[\"y\"])\n",
    "    y = train_data.y\n",
    "    # iterate over the splits\n",
    "\n",
    "    preds = []\n",
    "    gt = []\n",
    "    for train_index, test_index in tqdm(loo.split(X)):\n",
    "        # get the training and test data for this split\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # fit the model on the training data and score it on the test data\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds.append(clf.predict(X_test))\n",
    "        gt.append(y_test)\n",
    "        \n",
    "\n",
    "    # calculate and print the mean score\n",
    "    return r2_score(gt,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(max_depth=3,random_state=i)\n",
    "LOOCV(clf,gbwp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf,gbwp,gbw = get_topic_week(df,'Ausland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
